{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Spark\n",
    "#### Objective: Build a classification algorithm using Spark ML\n",
    "#### As part of this activity,\n",
    "#### 1. Read data, understand data using exploratory data analysis.\n",
    "#### 2. Do necessary pre-processing and build machine learning classification algorithm using the libraries available in SparkML. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Spark Environment\n",
    "Configure environment variables, Make sure you provide the correct Spark installation path/location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Set Python - Spark environment. Resolve necessary dependencies specific to Spark HBase Connector.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.6-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the Spark Session\n",
    "#### Create and Initialize Spark Driver\n",
    "Creating a spark app that will run locally and will use as many threads as there are cores using local[*] :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create SparkContext, SparkSession\n",
    "from os.path import expanduser, join, abspath\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# warehouse_location points to the default location for managed databases and tables\n",
    "warehouse_location = 'hdfs:///apps/hive/warehouse/'\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Machine Learning Example using Spark ML\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Spark Driver -  Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c.insofe.edu.in:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.2.6.5.0-292</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Machine Learning Example using Spark ML</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2a002d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Verify Spark Session\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and analyse using SparkML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bank Marketing Example\n",
    "we are going to use an example throughout this activity for bank marketing.\n",
    "Signet bank is the company that started with capital one.\n",
    "\n",
    "It was a small unknown bank that learned based on its prior data can actually better market to right customers to give them credit cards\n",
    "they did this back in 1980s before data science is really a thing and since then they've grown to one of largest credit card brands in the world largely based on using data.\n",
    "\n",
    "**“data on the specific transactions of a bank’s customers can improve models for deciding what product offers to make.”** - Data Science for Business, Provost, Foster - O’Reilly 2013\n",
    "\n",
    "#### But …\n",
    "**given a set of examples how do I get training data to the function (i.e. model)?**\n",
    "![ML4](../Images/ml4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Representation\n",
    "- **Pandas** - DataFrames represented on a single machine as Python data structures\n",
    "- **RDDs** - Spark’s foundational structure Resilient Distributed Dataset is represented as a reference to partitioned data without types\n",
    "- **DataFrames** - Spark’s strongly typed optimized distributed collection of rows\n",
    "\n",
    "**All ML Algorithms need to represent data as vectors (array of Double values) in order to train machine learning algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipelines\n",
    "ML Pipelines provide a uniform set of high-level APIs built on top of DataFrames that help users create and tune practical machine learning pipelines and this concept is mostly inspired by the scikit-learn project.\n",
    "\n",
    "![MLP1](../Images/mlp1.png)\n",
    "<br>\n",
    "![MLP2](../Images/mlp2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPARK Architecture\n",
    "![Spark Architecture](../Images/sa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single vs Distributed Machine Learning\n",
    "\n",
    "#### Single Machine Learning\n",
    "- In a single machine algorithm such as scikit-learn, the data isloaded into the memory of a single machine (usually as Pandas or\n",
    "NumPy vectors)\n",
    "- The single machine algorithm iterates (loops) over the data in memory and using a single thread (sometimes multicore) takes a\n",
    "\"guess\" at the equation\n",
    "- The error is calculated and if the error from the previous iteration is less than the tolerance or the iterations are >= max iterations then STOP<br>\n",
    "\n",
    "#### Distributed Machine Learning\n",
    "- In Distributed Machine Learning like Spark MLlib, the data is represented as an RDD or a DataFrame typically in distributed file storage such as S3, Blob Store or HDFS\n",
    "- As a best practice, you should cache the data in memory across the nodes so that multiple iterations don’t have to query the disk each time\n",
    "- The calculation of the gradients is distributed across all the nodes using Spark's distributed compute engine (similar to MapReduce)\n",
    "- After each iteration, the results return to the driver and iterations continue until eithermax_iter or tol is reached\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "![Logistic Regression](../Images/alg1.png)\n",
    "![Logistic Regression Implementations](../Images/alg2.png)\n",
    "![Random Forest](../Images/alg3.png)\n",
    "![Distributed Random Forest](../Images/alg4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark ML Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dependent Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import StringIO\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='mtest', api_key='VLkBLZlr9yD6tgcbEiTS')\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.plotly as py\n",
    "import plotly.offline as pyoff\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Initializing some settings\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(color_codes=True)\n",
    "warnings.filterwarnings('ignore')\n",
    "pyoff.init_notebook_mode(connected=True)\n",
    "get_ipython().magic('matplotlib inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement\n",
    "The dataset is from a bank, data related to direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, to access if the product (bank term deposit) would be (or not) subscribed. The data and attribute description are in the folder.\n",
    "\n",
    "#### Dataset Description\n",
    "The dataset has the following attributes:\n",
    "<br>1 - unique sequence id\n",
    "<br>2 - age (numeric)\n",
    "<br>3 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\", \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\")\n",
    "<br>4 - marital_status : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "<br>5 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "<br>6 - default: has credit in default? (binary: \"yes\",\"no\")\n",
    "<br>7 - balance: average yearly balance, in euros (numeric)\n",
    "<br>8 - housing: has housing loan? (binary: \"yes\",\"no\")\n",
    "<br>9 - loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "<br>10 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\")\n",
    "<br>11 - day: last contact day of the month (numeric)\n",
    "<br>12 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "<br>13 - duration: last contact duration, in seconds (numeric)\n",
    "<br>14 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "<br>15 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
    "<br>16 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "<br>17 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "<br>**18 - opened_new_td_act_no_yes - has the client subscribed to a term deposit? (binary: \"yes\",\"no\")**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<font color=\"blue\">\n",
    "<br>\n",
    "The idea is we have set of information about a person whether its their age the job they have the marital status whether they have loan with the bank or not etc. we're trying to decide here is whether this person open a new deposit account with this bank.\n",
    "</br><br><br>\n",
    "So the theory here is that if I can better target the right customers with the right offer at right time they'll convert over to actually open a deposit account with the bank so that I don't have to reach out whole population and waste a lot of money with ads or mailer or what ever have you but target only the perspective customers.\n",
    "</br></font>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the schema for the dataset and use this to create the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define Schema\n",
    "bankDataSchema = StructType([\n",
    "         StructField(\"age\", IntegerType(), True),\n",
    "         StructField(\"job\", StringType(), True),\n",
    "         StructField(\"marital_status\", StringType(), True),\n",
    "         StructField(\"education\", StringType(), True),\n",
    "         StructField(\"default\", StringType(), True),\n",
    "         StructField(\"balance\", DoubleType(), True),\n",
    "         StructField(\"housing\", StringType(), True),\n",
    "         StructField(\"loan\", StringType(), True),        \n",
    "         StructField(\"contact\", StringType(), True),\n",
    "         StructField(\"day\", IntegerType(), True),\n",
    "         StructField(\"month\", StringType(), True),\n",
    "         StructField(\"duration\", DoubleType(), True),\n",
    "         StructField(\"campaign\", DoubleType(), True),\n",
    "         StructField(\"pdays\", DoubleType(), True),\n",
    "         StructField(\"previous\", DoubleType(), True),\n",
    "         StructField(\"poutcome\", StringType(), True),\n",
    "         StructField(\"opened_new_td_act_no_yes\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the above schema read data and create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading and create from local files\n",
    "bankDF = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"false\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .load(\"file:///home/rameshm/Datasets/bank_data.csv\", schema = bankDataSchema)\n",
    "\n",
    "# Reading and create from HDFS\n",
    "# bankDF = spark.read.format(\"csv\")\\\n",
    "#         .option(\"header\", \"false\")\\\n",
    "#         .option(\"inferSchema\", \"true\")\\\n",
    "#         .load(\"/user/rameshm/<path>/bank_data.csv\", schema = bankDataSchema)\n",
    "        \n",
    "# bankDF = spark.read.format(\"csv\")\\\n",
    "#         .option(\"header\", \"false\")\\\n",
    "#         .option(\"inferSchema\", \"true\")\\\n",
    "#         .load(\"hdfs:///user/rameshm/<path>/bank_data.csv\", schema = bankDataSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: double (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- campaign: double (nullable = true)\n",
      " |-- pdays: double (nullable = true)\n",
      " |-- previous: double (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- opened_new_td_act_no_yes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bankDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check datatype of each column/field/attribute/feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital_status', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('balance', 'double'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('day', 'int'),\n",
       " ('month', 'string'),\n",
       " ('duration', 'double'),\n",
       " ('campaign', 'double'),\n",
       " ('pdays', 'double'),\n",
       " ('previous', 'double'),\n",
       " ('poutcome', 'string'),\n",
       " ('opened_new_td_act_no_yes', 'string')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankDF.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cache DataFrame\n",
    "Calling cache on the DataFrame will make sure we persist it in memory the first time it is used.\n",
    "<br>The following uses will be able to read from memory, instead of re-reading the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, job: string, marital_status: string, education: string, default: string, balance: double, housing: string, loan: string, contact: string, day: int, month: string, duration: double, campaign: double, pdays: double, previous: double, poutcome: string, opened_new_td_act_no_yes: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankDF.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify first few records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=30, job=u'unemployed', marital_status=u'married', education=u'primary', default=u'no', balance=1787.0, housing=u'no', loan=u'no', contact=u'cellular', day=19, month=u'oct', duration=79.0, campaign=1.0, pdays=-1.0, previous=0.0, poutcome=u'unknown', opened_new_td_act_no_yes=u'no'),\n",
       " Row(age=33, job=u'services', marital_status=u'married', education=u'secondary', default=u'no', balance=4789.0, housing=u'yes', loan=u'yes', contact=u'cellular', day=11, month=u'may', duration=220.0, campaign=1.0, pdays=339.0, previous=4.0, poutcome=u'failure', opened_new_td_act_no_yes=u'no')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To Show first n observations\n",
    "## Use head operation to see first n observations (say, 10 observations). \n",
    "## Head operation in PySpark is similar to head operation in Pandas.\n",
    "bankDF.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "|age|       job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|opened_new_td_act_no_yes|\n",
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "| 30|unemployed|       married|  primary|     no| 1787.0|     no|  no|cellular| 19|  oct|    79.0|     1.0| -1.0|     0.0| unknown|                      no|\n",
      "| 33|  services|       married|secondary|     no| 4789.0|    yes| yes|cellular| 11|  may|   220.0|     1.0|339.0|     4.0| failure|                      no|\n",
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Above results are comprised of row like format. \n",
    "## To see the result in more interactive manner (rows under the columns), Use the show operation. \n",
    "## Show operation on train and take first 5 rows of it. \n",
    "bankDF.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the total rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records count is 4521\n",
      "Total Columns count is 17\n",
      "\n",
      "\n",
      "Columns are: ['age', 'job', 'marital_status', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'opened_new_td_act_no_yes'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## To Count the number of rows in DataFrame\n",
    "print('Total records count is {}'.format(bankDF.count()))\n",
    "## Columns count and column names\n",
    "print(\"Total Columns count is {}\".format(len(bankDF.columns)))\n",
    "print(\"\\n\\nColumns are: {} \\n\".format(bankDF.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+------------------------+\n",
      "|summary|               age|    job|marital_status|education|default|           balance|housing|loan| contact|               day|month|          duration|          campaign|             pdays|          previous|poutcome|opened_new_td_act_no_yes|\n",
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+------------------------+\n",
      "|  count|              4521|   4521|          4521|     4521|   4521|              4521|   4521|4521|    4521|              4521| 4521|              4521|              4521|              4521|              4521|    4521|                    4521|\n",
      "|   mean| 41.17009511170095|   null|          null|     null|   null|1422.6578190665782|   null|null|    null|15.915284229152842| null|263.96129174961294| 2.793629727936297|39.766644547666445|0.5425790754257908|    null|                    null|\n",
      "| stddev|10.576210958711263|   null|          null|     null|   null|3009.6381424673395|   null|null|    null| 8.247667327229934| null|259.85663262468216|3.1098066601885823|100.12112444301656|1.6935623506071211|    null|                    null|\n",
      "|    min|                19| admin.|      divorced|  primary|     no|           -3313.0|     no|  no|cellular|                 1|  apr|               4.0|               1.0|              -1.0|               0.0| failure|                      no|\n",
      "|    max|                87|unknown|        single|  unknown|    yes|           71188.0|    yes| yes| unknown|                31|  sep|            3025.0|              50.0|             871.0|              25.0| unknown|                     yes|\n",
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## To get the summary statistics (mean, standard deviance, min ,max , count) of columns in a DataFrame\n",
    "bankDF.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----+------------------+------------------+\n",
      "|summary|               age|loan|           balance|             pdays|\n",
      "+-------+------------------+----+------------------+------------------+\n",
      "|  count|              4521|4521|              4521|              4521|\n",
      "|   mean| 41.17009511170095|null|1422.6578190665782|39.766644547666445|\n",
      "| stddev|10.576210958711263|null|3009.6381424673395|100.12112444301656|\n",
      "|    min|                19|  no|           -3313.0|              -1.0|\n",
      "|    max|                87| yes|           71188.0|             871.0|\n",
      "+-------+------------------+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Verify summary stats for few fields\n",
    "bankDF.describe().select('summary', 'age', 'loan', 'balance', 'pdays').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distinct values count in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "|age|job|marital_status|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|opened_new_td_act_no_yes|\n",
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "| 67| 12|             3|        4|      2|   2353|      2|   2|      3| 31|   12|     875|      32|  292|      24|       4|                       2|\n",
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Find the Distinct values count in each column\n",
    "bankDF.agg(*(countDistinct(col(c)).alias(c) for c in bankDF.columns)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "|age|    job|marital_status|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|opened_new_td_act_no_yes|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "| 87|unknown|        single|  unknown|    yes|71188.0|    yes| yes|unknown| 31|  sep|  3025.0|    50.0|871.0|    25.0| unknown|                     yes|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Find maximum value in each column\n",
    "bankDF.agg(*(max(col(c)).alias(c) for c in bankDF.columns)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "|age|   job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|opened_new_td_act_no_yes|\n",
      "+---+------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "| 19|admin.|      divorced|  primary|     no|-3313.0|     no|  no|cellular|  1|  apr|     4.0|     1.0| -1.0|     0.0| failure|                      no|\n",
      "+---+------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Find maximum value in each column\n",
    "bankDF.agg(*(min(col(c)).alias(c) for c in bankDF.columns)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "The minimum value in the balance column is negative\n",
    "<br>Verify how many such negative values exists in the balance column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of negative values in balance column are: 366\n"
     ]
    }
   ],
   "source": [
    "print(\"Total count of negative values in balance column are: {}\".format(bankDF.where(bankDF.balance < 0).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace the negative balances with the ZEROES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Replace negative balances with zeroes\n",
    "from pyspark.sql.functions import when\n",
    "bankDF = bankDF.withColumn('balance', when(bankDF.balance > 0, bankDF.balance).otherwise(0))\n",
    "zeroBalance = bankDF.where(bankDF.balance < 0)\n",
    "zeroBalance.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a table/view to run sql queries on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create view/table\n",
    "bankDF.createOrReplaceTempView(\"bankDFTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|opened_new_td_act_no_yes|Count|\n",
      "+------------------------+-----+\n",
      "|                      no| 4000|\n",
      "|                     yes|  521|\n",
      "+------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Multiple ways of referring a column in a dataframe\n",
    "resultDF = spark.sql(\"\"\"\n",
    "SELECT opened_new_td_act_no_yes, COUNT(*) AS Count\n",
    "FROM bankDFTable\n",
    "GROUP BY opened_new_td_act_no_yes\n",
    "\"\"\")\n",
    "\n",
    "resultDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mtest/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdDF = resultDF.toPandas()\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=pdDF['opened_new_td_act_no_yes'], # assign x as the dataframe column 'x'\n",
    "        y=pdDF['Count']\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(title='Term Deposit Opted Yes/No Counts',)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='plot_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair wise frequency between Target (opened_new_td_act_no_yes) and loan columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultDF = bankDF.crosstab(\"opened_new_td_act_no_yes\", \"loan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+----+---+\n",
      "|opened_new_td_act_no_yes_loan|  no|yes|\n",
      "+-----------------------------+----+---+\n",
      "|                          yes| 478| 43|\n",
      "|                           no|3352|648|\n",
      "+-----------------------------+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mtest/10.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdDF = resultDF.toPandas()\n",
    "pdDF.columns = ['opened_new_td_act_no_yes', 'No_Existing_Loans', 'Existing_Loan']\n",
    "trace1 = go.Bar(\n",
    "    x=['Opted for TD', 'Not Opted for TD'],\n",
    "    y=pdDF['No_Existing_Loans'],\n",
    "    name='No Existing Loans'\n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x=['Opted for TD', 'Not Opted for TD'],\n",
    "    y=pdDF['Existing_Loan'],\n",
    "    name='Existing Loans'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    title='Term Deposit Accounts vs Existing Loan Counts',\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='plot_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Deposit Opted Counts for different job categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultDF = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    job,\n",
    "    COUNT(*) AS term_deposit_yes_cnt\n",
    "    FROM bankDFTable \n",
    "    WHERE opened_new_td_act_no_yes = \"yes\"\n",
    "    GROUP BY job\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mtest/12.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdDF = resultDF.toPandas()\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=pdDF['job'], # assign x as the dataframe column 'x'\n",
    "        y=pdDF['term_deposit_yes_cnt']\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(title='Term Deposit Opted Counts in each Job Category',)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='plot_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Deposit Not-Opted Counts for different job categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultDF = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    job,\n",
    "    COUNT(*) AS term_deposit_no_cnt\n",
    "    FROM bankDFTable \n",
    "    WHERE opened_new_td_act_no_yes = \"no\"\n",
    "    GROUP BY job\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mtest/14.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdDF = resultDF.toPandas()\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=pdDF['job'], # assign x as the dataframe column 'x'\n",
    "        y=pdDF['term_deposit_no_cnt']\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(title='Term Deposit Count in each Job Category',)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='plot_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term Deposits Counts for different education levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultDF = bankDF.filter(expr(\"opened_new_td_act_no_yes = 'yes'\")).groupBy(\"education\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|education|count|\n",
      "+---------+-----+\n",
      "|  unknown|   19|\n",
      "| tertiary|  193|\n",
      "|secondary|  245|\n",
      "|  primary|   64|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mtest/16.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdDF = resultDF.toPandas()\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=pdDF['education'], # assign x as the dataframe column 'x'\n",
    "        y=pdDF['count']\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(title='Term Deposit Opted Count in each Education Level',)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='plot_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultDF = bankDF.filter(expr(\"opened_new_td_act_no_yes = 'no'\")).groupBy(\"education\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mtest/18.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdDF = resultDF.toPandas()\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=pdDF['education'], # assign x as the dataframe column 'x'\n",
    "        y=pdDF['count']\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(title='Term Deposit Not-Opted Count in each Education Level',)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='plot_6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair wise frequency between Target (opened_new_td_act_no_yes) and marital_status columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultDF = bankDF.crosstab('opened_new_td_act_no_yes', 'marital_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+--------+-------+------+\n",
      "|opened_new_td_act_no_yes_marital_status|divorced|married|single|\n",
      "+---------------------------------------+--------+-------+------+\n",
      "|                                    yes|      77|    277|   167|\n",
      "|                                     no|     451|   2520|  1029|\n",
      "+---------------------------------------+--------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultDF = spark.sql(\"\"\"\n",
    "SELECT opened_new_td_act_no_yes,\n",
    "    SUM(CASE WHEN marital_status = 'divorced' THEN 1 ELSE 0 END) divorced_Count,\n",
    "    SUM(CASE WHEN marital_status = 'married' THEN 1 ELSE 0 END) married_Count,\n",
    "    SUM(CASE WHEN marital_status = 'single' THEN 1 ELSE 0 END) single_Count\n",
    "from bankDFTable\n",
    "GROUP BY opened_new_td_act_no_yes\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------+-------------+------------+\n",
      "|opened_new_td_act_no_yes|divorced_Count|married_Count|single_Count|\n",
      "+------------------------+--------------+-------------+------------+\n",
      "|                      no|           451|         2520|        1029|\n",
      "|                     yes|            77|          277|         167|\n",
      "+------------------------+--------------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mtest/20.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdDF = resultDF.toPandas()\n",
    "trace1 = go.Bar(\n",
    "    x=pdDF['opened_new_td_act_no_yes'],\n",
    "    y=pdDF['divorced_Count'],\n",
    "    name='Divorced Count'\n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x=pdDF['opened_new_td_act_no_yes'],\n",
    "    y=pdDF['married_Count'],\n",
    "    name='Married Count'\n",
    ")\n",
    "\n",
    "trace3 = go.Bar(\n",
    "    x=pdDF['opened_new_td_act_no_yes'],\n",
    "    y=pdDF['single_Count'],\n",
    "    name='Single Count'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2, trace3]\n",
    "layout = go.Layout(\n",
    "    title='term depoisit opted/not-opted vs marital_status Counts',\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='plot_7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair wise frequency between Target (opened_new_td_act_no_yes) and default columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+----+---+\n",
      "|default_opened_new_td_act_no_yes|  no|yes|\n",
      "+--------------------------------+----+---+\n",
      "|                             yes|  67|  9|\n",
      "|                              no|3933|512|\n",
      "+--------------------------------+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultDF = bankDF.crosstab('default', 'opened_new_td_act_no_yes')\n",
    "resultDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mtest/22.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdDF = resultDF.toPandas()\n",
    "trace1 = go.Bar(\n",
    "    x=['Defaulted_Yes', 'Defaulted_No'],\n",
    "    y=pdDF['no'],\n",
    "    name='Not Opted'\n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x=['Defaulted_Yes', 'Defaulted_No'],\n",
    "    y=pdDF['yes'],\n",
    "    name='Opted'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    title='Default vs term deposit Counts',\n",
    "    barmode='group'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='plot_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Spark DataFrame into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>opened_new_td_act_no_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job marital_status  education default  balance housing loan  \\\n",
       "0   30   unemployed        married    primary      no   1787.0      no   no   \n",
       "1   33     services        married  secondary      no   4789.0     yes  yes   \n",
       "2   35   management         single   tertiary      no   1350.0     yes   no   \n",
       "3   30   management        married   tertiary      no   1476.0     yes  yes   \n",
       "4   59  blue-collar        married  secondary      no      0.0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  \\\n",
       "0  cellular   19   oct      79.0       1.0   -1.0       0.0  unknown   \n",
       "1  cellular   11   may     220.0       1.0  339.0       4.0  failure   \n",
       "2  cellular   16   apr     185.0       1.0  330.0       1.0  failure   \n",
       "3   unknown    3   jun     199.0       4.0   -1.0       0.0  unknown   \n",
       "4   unknown    5   may     226.0       1.0   -1.0       0.0  unknown   \n",
       "\n",
       "  opened_new_td_act_no_yes  \n",
       "0                       no  \n",
       "1                       no  \n",
       "2                       no  \n",
       "3                       no  \n",
       "4                       no  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankDF_pd = bankDF.toPandas()\n",
    "bankDF_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derive Correlations for the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084202</td>\n",
       "      <td>-0.017853</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>-0.005148</td>\n",
       "      <td>-0.008894</td>\n",
       "      <td>-0.003511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.084202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007595</td>\n",
       "      <td>-0.015195</td>\n",
       "      <td>-0.010840</td>\n",
       "      <td>0.008616</td>\n",
       "      <td>0.026031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>-0.017853</td>\n",
       "      <td>-0.007595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024629</td>\n",
       "      <td>0.160706</td>\n",
       "      <td>-0.094352</td>\n",
       "      <td>-0.059114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>-0.002367</td>\n",
       "      <td>-0.015195</td>\n",
       "      <td>-0.024629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.068382</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.018080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>-0.005148</td>\n",
       "      <td>-0.010840</td>\n",
       "      <td>0.160706</td>\n",
       "      <td>-0.068382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093137</td>\n",
       "      <td>-0.067833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays</th>\n",
       "      <td>-0.008894</td>\n",
       "      <td>0.008616</td>\n",
       "      <td>-0.094352</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>-0.093137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>-0.003511</td>\n",
       "      <td>0.026031</td>\n",
       "      <td>-0.059114</td>\n",
       "      <td>0.018080</td>\n",
       "      <td>-0.067833</td>\n",
       "      <td>0.577562</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age   balance       day  duration  campaign     pdays  previous\n",
       "age       1.000000  0.084202 -0.017853 -0.002367 -0.005148 -0.008894 -0.003511\n",
       "balance   0.084202  1.000000 -0.007595 -0.015195 -0.010840  0.008616  0.026031\n",
       "day      -0.017853 -0.007595  1.000000 -0.024629  0.160706 -0.094352 -0.059114\n",
       "duration -0.002367 -0.015195 -0.024629  1.000000 -0.068382  0.010380  0.018080\n",
       "campaign -0.005148 -0.010840  0.160706 -0.068382  1.000000 -0.093137 -0.067833\n",
       "pdays    -0.008894  0.008616 -0.094352  0.010380 -0.093137  1.000000  0.577562\n",
       "previous -0.003511  0.026031 -0.059114  0.018080 -0.067833  0.577562  1.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = bankDF_pd.corr()\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7e9e290>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5429610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.set(style=\"white\")\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(correlations, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "    \n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(1000, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(correlations, mask=mask, cmap=cmap, vmax=.5, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mtest/24.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Heatmap(z=[correlations['age'], correlations['balance'],correlations['day'],correlations['duration'],\n",
    "                      correlations['campaign'],correlations['pdays'],correlations['previous']],\n",
    "                   x=['age','balance','day','duration','campaign','pdays','previous'],\n",
    "                   y=['age','balance','day','duration','campaign','pdays','previous'])\n",
    "data=[trace]\n",
    "layout = go.Layout(title='Heat Map',)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='plot_9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Sampling\n",
    "20% from 0 class\n",
    "<br> 70% from 1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total records are: ', 925)\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "|age|     job|marital_status|education|default|balance|housing|loan|  contact|day|month|duration|campaign|pdays|previous|poutcome|opened_new_td_act_no_yes|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "| 43|  admin.|       married|secondary|     no|  264.0|    yes|  no| cellular| 17|  apr|   113.0|     2.0| -1.0|     0.0| unknown|                      no|\n",
      "| 20| student|        single|secondary|     no|  502.0|     no|  no| cellular| 30|  apr|   261.0|     1.0| -1.0|     0.0| unknown|                     yes|\n",
      "| 44|services|        single|secondary|     no|  106.0|     no|  no|  unknown| 12|  jun|   109.0|     2.0| -1.0|     0.0| unknown|                      no|\n",
      "| 68| retired|      divorced|secondary|     no| 4189.0|     no|  no|telephone| 14|  jul|   897.0|     2.0| -1.0|     0.0| unknown|                     yes|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_data = bankDF.sampleBy(\"opened_new_td_act_no_yes\", fractions={'no': 0.12, 'yes': 0.9}, seed=12345)\n",
    "print('Total records are: ', sample_data.count())\n",
    "sample_data.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+\n",
      "|opened_new_td_act_no_yes|count|\n",
      "+------------------------+-----+\n",
      "|                      no|  453|\n",
      "|                     yes|  472|\n",
      "+------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_data.groupBy(\"opened_new_td_act_no_yes\").count().orderBy(\"opened_new_td_act_no_yes\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "|age|job|marital_status|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|opened_new_td_act_no_yes|\n",
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "|  0|  0|             0|        0|      0|      0|      0|   0|      0|  0|    0|       0|       0|    0|       0|       0|                       0|\n",
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bankDF.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in bankDF.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Null values - if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Before Dropping Null Values', 4521)\n",
      "('After Dropping Null Values', 4521)\n"
     ]
    }
   ],
   "source": [
    "data_df = bankDF.na.drop( how = 'any' )\n",
    "print('Before Dropping Null Values', bankDF.count())\n",
    "print('After Dropping Null Values', data_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and test sets (30% held out for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = bankDF.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "|age|    job|marital_status|education|default|balance|housing|loan|  contact|day|month|duration|campaign|pdays|previous|poutcome|opened_new_td_act_no_yes|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "| 19|student|        single|secondary|     no|  302.0|     no|  no| cellular| 16|  jul|   205.0|     1.0| -1.0|     0.0| unknown|                     yes|\n",
      "| 19|student|        single|  unknown|     no|    0.0|     no|  no| cellular| 11|  feb|   123.0|     3.0| -1.0|     0.0| unknown|                      no|\n",
      "| 19|student|        single|  unknown|     no| 1169.0|     no|  no| cellular|  6|  feb|   463.0|    18.0| -1.0|     0.0| unknown|                      no|\n",
      "| 20|student|        single|secondary|     no|  291.0|     no|  no|telephone| 11|  may|   172.0|     5.0|371.0|     5.0| failure|                      no|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "|age|     job|marital_status|education|default|balance|housing|loan|  contact|day|month|duration|campaign|pdays|previous|poutcome|opened_new_td_act_no_yes|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "| 19| student|        single|  primary|     no|  103.0|     no|  no| cellular| 10|  jul|   104.0|     2.0| -1.0|     0.0| unknown|                     yes|\n",
      "| 20| student|        single|secondary|     no|  502.0|     no|  no| cellular| 30|  apr|   261.0|     1.0| -1.0|     0.0| unknown|                     yes|\n",
      "| 21|services|        single|secondary|     no|  361.0|     no|  no|telephone|  5|  jun|   329.0|     1.0| 95.0|     1.0|   other|                      no|\n",
      "| 21| student|        single|secondary|     no|    6.0|     no|  no|  unknown|  9|  may|   622.0|     1.0| -1.0|     0.0| unknown|                      no|\n",
      "+---+--------+--------------+---------+-------+-------+-------+----+---------+---+-----+--------+--------+-----+--------+--------+------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testData.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define PipeLines\n",
    "<br>Stages:\n",
    "    -  Preprocessing\n",
    "    -  Model Building & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Categorical and Numerical Columns from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_Var_Names = ['job', 'marital_status', 'education', 'default', 'housing', \n",
    "                 'day', 'contact', 'month', 'poutcome']\n",
    "\n",
    "num_Var_Names = ['age', 'balance', 'duration', 'previous', 'pdays', 'campaign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use VectorAssembler to combine a given list of numcolumns into a single vector column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vector_assembler_NumVars = VectorAssembler(inputCols=num_Var_Names, outputCol=\"num_features_all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale all the numeric attributes using MinMaxScaler\n",
    "MinMaxScaler transforms a dataset of Vector rows, rescaling each feature to a specific range (often [0, 1]). \n",
    "<br>MinMaxScaler computes summary statistics on a data set and produces a MinMaxScalerModel. \n",
    "<br>The model can then transform each feature individually such that it is in the given range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "min_Max_Scalar_NumVars = MinMaxScaler(inputCol=\"num_features_all\", outputCol = \"scaled_num_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert Categorical Variables into Numeric\n",
    "Dummify (encode) the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "indexers_Cat  = [StringIndexer(inputCol=cat_Var_Name, outputCol=\"{0}_index\".format(cat_Var_Name)) \n",
    "                 for cat_Var_Name in cat_Var_Names ]\n",
    "\n",
    "encoders_Cat  = [OneHotEncoder(inputCol=indexer.getOutputCol(), \n",
    "                               outputCol=\"{0}_vec\".format(indexer.getInputCol())) \n",
    "                 for indexer in indexers_Cat]\n",
    "\n",
    "assembler_Cat = VectorAssembler(inputCols=[encoder.getOutputCol() \n",
    "                                           for encoder in encoders_Cat], outputCol=\"cat_features\")\n",
    "\n",
    "assembler     = VectorAssembler(inputCols=[\"scaled_num_features\",\"cat_features\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode Target Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexer_Label = StringIndexer(inputCol=\"opened_new_td_act_no_yes\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine numerical attributes into a vector\n",
    "# Scale above vector\n",
    "# String Indexing on Categorical attributes\n",
    "# OneHot Encoder on the above indexers\n",
    "# Combine all the encoded Categorical vectors into a single  vector\n",
    "# Combine both Numerical and Categorical into a one vector\n",
    "# Target attribute\n",
    "preprocessiong_Stages = [vector_assembler_NumVars] +\\\n",
    "                        [min_Max_Scalar_NumVars] +\\\n",
    "                        indexers_Cat + encoders_Cat +\\\n",
    "                        [assembler_Cat] +\\\n",
    "                        [assembler] +\\\n",
    "                        [indexer_Label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logistic Regression](../Images/lrc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "lr_Pipeline = Pipeline(stages=preprocessiong_Stages+[lr])\n",
    "\n",
    "lr_Pipeline_model = lr_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.3008025816647106,-3.566578592895943,12.6514337781419,1.3395352501724418,1.3479307007418753,-5.985402702348752,0.28520549650335913,-0.2782036826211365,0.04785329959150912,-0.11959347354438611,0.10435381201629236,1.0554573538202996,0.11272080019929473,-0.2683724459578257,-0.6942261559755067,-0.16035981591735785,0.5161690556447251,-0.33471558581937233,-0.15555100402798883,0.19706160762465103,0.3855204734778827,0.19307260803646265,0.4166454457072571,-0.4266604564647547,-0.5025141193677509,0.5224353205421683,-0.5970224857676252,-0.3649157263111622,0.3381536783809398,-0.05668181564482086,-0.934719721911264,0.5446442203437869,-0.4135707234254122,-0.2207758334720934,0.5630978668563787,0.11045159598991844,-0.16768981211016348,-0.08080802404507179,-0.3057971998822308,-0.13611055197004243,-0.2006215808910109,0.3816616620287133,0.08126665584116127,-0.5562480557251865,0.5411427524802767,0.29793060713313735,-0.45572080711904595,-0.4321930706745753,0.36016622418858896,0.5855175628668527,0.600827957257231,-0.6776831097882451,1.052990261336045,0.08940636445426342,0.6200603116191711,-1.196527571776644,-0.2231146839883329,-0.6763296586370828,0.00499172947282602,0.857864814362211,-0.3915365107999028,0.36816434919698193,0.3612444762152637,-1.1584990266960087,1.6875889192306306,0.9054009691317877,1.661333253881069,-1.9799790736658773,-2.5171133567413033,-1.8605878332155512]\n",
      "Intercept: -2.01496567932\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: \" + str(lr_Pipeline_model.stages[-1].coefficients))\n",
    "print(\"Intercept: \" + str(lr_Pipeline_model.stages[-1].intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_lr = lr_Pipeline_model.transform(trainingData)\n",
    "test_predictions_lr = lr_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+------------------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|age|    job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|opened_new_td_act_no_yes|    num_features_all| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|day_index|contact_index|month_index|poutcome_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|        cat_features|            features|label|       rawPrediction|         probability|prediction|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+------------------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "| 19|student|        single|  primary|     no|  103.0|     no|  no|cellular| 10|  jul|   104.0|     2.0| -1.0|     0.0| unknown|                     yes|[19.0,103.0,104.0...|[0.0,0.0014468730...|     10.0|                 1.0|            2.0|          0.0|          1.0|     28.0|          0.0|        1.0|           0.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[2],[1.0])|(1,[0],[1.0])|  (1,[],[])|(30,[28],[1.0])|(2,[0],[1.0])|(11,[1],[1.0])|(3,[0],[1.0])|(64,[10,12,15,16,...|(70,[1,2,5,16,18,...|  1.0|[1.73641621695143...|[0.85023128609824...|       0.0|\n",
      "| 20|student|        single|secondary|     no|  502.0|     no|  no|cellular| 30|  apr|   261.0|     1.0| -1.0|     0.0| unknown|                     yes|[20.0,502.0,261.0...|[0.01538461538461...|     10.0|                 1.0|            0.0|          0.0|          1.0|     10.0|          0.0|        5.0|           0.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(30,[10],[1.0])|(2,[0],[1.0])|(11,[5],[1.0])|(3,[0],[1.0])|(64,[10,12,13,16,...|(70,[0,1,2,16,18,...|  1.0|[0.42280321948492...|[0.60415384069846...|       0.0|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+------------------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_lr.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.908888180949\n",
      "Train Error = 0.0911118\n",
      "Test set accuracy = 0.887843704776\n",
      "Test Error = 0.112156\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictionAndLabels_train_lr = train_predictions_lr.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "train_accuracy_lr = evaluator.evaluate(predictionAndLabels_train_lr)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracy_lr))\n",
    "print(\"Train Error = %g\" % (1.0 - train_accuracy_lr))\n",
    "\n",
    "predictionAndLabels_test_lr = test_predictions_lr.select(\"prediction\", \"label\")\n",
    "test_accuracy_lr = evaluator.evaluate(predictionAndLabels_test_lr)\n",
    "print(\"Test set accuracy = \" + str(test_accuracy_lr))\n",
    "print(\"Test Error = %g\" % (1.0 - test_accuracy_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METRICS\n",
    "Below we calculate some more metrics. The number of false and true positive and negative predictions is also useful:\n",
    "- **true positives (TP):** These are cases in which we predicted yes (they had term deposit), and they do had the \n",
    "- **true negatives (TN):** We predicted no, and they don't have the term deposit.\n",
    "- **false positives (FP):** We predicted yes, but they don't actually have the term deposit. (Also known as a \"Type I error.\")\n",
    "- **false negatives (FN):** We predicted no, but they actually do have the term deposit. (Also known as a \"Type II error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of metrics that are often computed from a confusion matrix for a binary classifier:\n",
    "    \n",
    "- **Accuracy:** Overall, how often is the classifier correct? (TP+TN)/total\n",
    "- **Misclassification Rate:** Overall, how often is it wrong? (FP+FN)/total\n",
    "    - equivalent to 1 minus Accuracy, also known as \"**Error Rate**\"\n",
    "- **True Positive Rate:** When it's actually yes, how often does it predict yes? TP/actual yes\n",
    "    - also known as \"**Sensitivity**\" or \"**Recall**\"\n",
    "- **False Positive Rate:** When it's actually no, how often does it predict yes? FP/actual no\n",
    "- **True Negative Rate:** When it's actually no, how often does it predict no? TN/actual no\n",
    "    - equivalent to 1 minus False Positive Rate, also known as \"**Specificity**\"\n",
    "- **Precision:** When it predicts yes, how often is it correct? TP/predicted yes\n",
    "- **F1 Score:** This is a weighted average of the true positive rate (recall) and precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN METRICS - LINEAR MODEL - BINOMIAL FAMILY\n",
      "True Positives: 121\n",
      "True Negatives: 2732\n",
      "False Positives: 56\n",
      "False Negatives: 230\n",
      "Total 3139\n",
      "Precission:  0.683615819209\n",
      "Recall:  0.344729344729\n",
      "F1 Score:  0.458333333333\n",
      "*****************************************************************************\n",
      "TEST METRICS - LINEAR MODEL - BINOMIAL FAMILY\n",
      "True Positives: 49\n",
      "True Negatives: 1178\n",
      "False Positives: 34\n",
      "False Negatives: 121\n",
      "Total 3139\n",
      "Precission:  0.590361445783\n",
      "Recall:  0.288235294118\n",
      "F1 Score:  0.387351778656\n"
     ]
    }
   ],
   "source": [
    "true_positive = predictionAndLabels_train_lr[(predictionAndLabels_train_lr.label == 1) & (predictionAndLabels_train_lr.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_train_lr[(predictionAndLabels_train_lr.label == 0) & (predictionAndLabels_train_lr.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_train_lr[(predictionAndLabels_train_lr.label == 0) & (predictionAndLabels_train_lr.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_train_lr[(predictionAndLabels_train_lr.label == 1) & (predictionAndLabels_train_lr.prediction == 0.0)].count()\n",
    "print \"TRAIN METRICS - LINEAR MODEL - BINOMIAL FAMILY\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_lr.count()\n",
    "precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))\n",
    "print(\"*****************************************************************************\")\n",
    "true_positive = predictionAndLabels_test_lr[(predictionAndLabels_test_lr.label == 1) & (predictionAndLabels_test_lr.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_test_lr[(predictionAndLabels_test_lr.label == 0) & (predictionAndLabels_test_lr.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_test_lr[(predictionAndLabels_test_lr.label == 0) & (predictionAndLabels_test_lr.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_test_lr[(predictionAndLabels_test_lr.label == 1) & (predictionAndLabels_test_lr.prediction == 0.0)].count()\n",
    "print \"TEST METRICS - LINEAR MODEL - BINOMIAL FAMILY\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_lr.count()\n",
    "precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.5])\\\n",
    "    .build()\n",
    "    \n",
    "lr_crossval = CrossValidator(estimator=lr_Pipeline,\n",
    "                             estimatorParamMaps=paramGrid,\n",
    "                             evaluator=evaluator,\n",
    "                             numFolds=2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run cross-validation, and choose the best set of parameters.\n",
    "lr_crossval_Model = lr_crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_lrcv = lr_crossval_Model.transform(trainingData)\n",
    "test_predictions_lrcv = lr_crossval_Model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.889136667729\n",
      "Test set accuracy = 0.876989869754\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_lrcv = train_predictions_lrcv.select(\"prediction\", \"label\")\n",
    "train_accuracycv = evaluator.evaluate(predictionAndLabels_train_lrcv)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracycv))\n",
    "\n",
    "predictionAndLabels_test_lrcv = test_predictions_lrcv.select(\"prediction\", \"label\")\n",
    "test_accuracycv = evaluator.evaluate(predictionAndLabels_test_lrcv)\n",
    "print(\"Test set accuracy = \" + str(test_accuracycv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pred_pandas = predictionAndLabels_train_lr.toPandas()\n",
    "train_actuals = train_pred_pandas.label.tolist()\n",
    "train_predictions = train_pred_pandas.prediction.tolist()\n",
    "\n",
    "\n",
    "test_pred_pandas = predictionAndLabels_test_lr.toPandas()\n",
    "test_actuals = test_pred_pandas.label.tolist()\n",
    "test_predictions = test_pred_pandas.prediction.tolist()\n",
    "from sklearn import metrics as smetrics\n",
    "cm = smetrics.confusion_matrix(train_actuals, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Not Approved  Approved\n",
      "Not Approved          2732        56\n",
      "Approved               230       121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x8d04450>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8ceea50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(cm)\n",
    "df_cm.index = ['Not Approved', 'Approved']\n",
    "df_cm.columns = ['Not Approved', 'Approved']\n",
    "names=['Not Approved', 'Approved']\n",
    "print(df_cm)\n",
    "fig = plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, annot=True,fmt=\"d\",annot_kws={\"size\": 20})# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multinomial Logistic Regression](../Images/mlrc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"binomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "mlr_Pipeline = Pipeline(stages=preprocessiong_Stages+[mlr])\n",
    "\n",
    "mlr_Pipeline_model = mlr_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_mlr = mlr_Pipeline_model.transform(trainingData)\n",
    "test_predictions_mlr = mlr_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: 1 X 70 CSRMatrix\n",
      "\n",
      "Intercept: [-2.0722935484145486]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: \" + str(mlr_Pipeline_model.stages[-1].coefficientMatrix))\n",
    "print(\"Intercept: \" + str(mlr_Pipeline_model.stages[-1].interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.888180949347\n",
      "Train Error = 0.111819\n",
      "Test set accuracy = 0.876989869754\n",
      "Test Error = 0.12301\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictionAndLabels_train_mlr = train_predictions_mlr.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(predictionAndLabels_train_mlr)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracy))\n",
    "print(\"Train Error = %g\" % (1.0 - train_accuracy))\n",
    "\n",
    "predictionAndLabels_test_mlr = test_predictions_mlr.select(\"prediction\", \"label\")\n",
    "test_accuracy = evaluator.evaluate(predictionAndLabels_test_mlr)\n",
    "print(\"Test set accuracy = \" + str(test_accuracy))\n",
    "print(\"Test Error = %g\" % (1.0 - test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN METRICS - LINEAR MODEL - MULTINOMIAL FAMILY\n",
      "True Positives: 0\n",
      "True Negatives: 2788\n",
      "False Positives: 0\n",
      "False Negatives: 351\n",
      "Total 3139\n",
      "Precission:  0.590361445783\n",
      "Recall:  0.0\n",
      "F1 Score:  0.0\n",
      "*****************************************************************************\n",
      "TEST METRICS - LINEAR MODEL - MULTINOMIAL FAMILY\n",
      "True Positives: 0\n",
      "True Negatives: 1212\n",
      "False Positives: 0\n",
      "False Negatives: 170\n",
      "Total 3139\n",
      "Precission:  0.590361445783\n",
      "Recall:  0.0\n",
      "F1 Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "true_positive = predictionAndLabels_train_mlr[(predictionAndLabels_train_mlr.label == 1) & (predictionAndLabels_train_mlr.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_train_mlr[(predictionAndLabels_train_mlr.label == 0) & (predictionAndLabels_train_mlr.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_train_mlr[(predictionAndLabels_train_mlr.label == 0) & (predictionAndLabels_train_mlr.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_train_mlr[(predictionAndLabels_train_mlr.label == 1) & (predictionAndLabels_train_mlr.prediction == 0.0)].count()\n",
    "print \"TRAIN METRICS - LINEAR MODEL - MULTINOMIAL FAMILY\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_mlr.count()\n",
    "#precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))\n",
    "print(\"*****************************************************************************\")\n",
    "true_positive = predictionAndLabels_test_mlr[(predictionAndLabels_test_mlr.label == 1) & (predictionAndLabels_test_mlr.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_test_mlr[(predictionAndLabels_test_mlr.label == 0) & (predictionAndLabels_test_mlr.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_test_mlr[(predictionAndLabels_test_mlr.label == 0) & (predictionAndLabels_test_mlr.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_test_mlr[(predictionAndLabels_test_mlr.label == 1) & (predictionAndLabels_test_mlr.prediction == 0.0)].count()\n",
    "print \"TEST METRICS - LINEAR MODEL - MULTINOMIAL FAMILY\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_mlr.count()\n",
    "#precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Decision Tree Classifier](../Images/dtc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_Pipeline = Pipeline(stages=preprocessiong_Stages+[dt]) \n",
    "\n",
    "dt_Pipeline_model = dt_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_dt = dt_Pipeline_model.transform(trainingData)\n",
    "test_predictions_dt = dt_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.915578209621\n",
      "Train Error = 0.0844218\n",
      "Test set accuracy = 0.886396526773\n",
      "Test Error = 0.113603\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictionAndLabels_train_dt = train_predictions_dt.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(predictionAndLabels_train_dt)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracy))\n",
    "print(\"Train Error = %g\" % (1.0 - train_accuracy))\n",
    "\n",
    "predictionAndLabels_test_dt = test_predictions_dt.select(\"prediction\", \"label\")\n",
    "test_accuracy = evaluator.evaluate(predictionAndLabels_test_dt)\n",
    "print(\"Test set accuracy = \" + str(test_accuracy))\n",
    "print(\"Test Error = %g\" % (1.0 - test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN METRICS - DECISSION TREE CLASSIFIER\n",
      "True Positives: 146\n",
      "True Negatives: 2728\n",
      "False Positives: 60\n",
      "False Negatives: 205\n",
      "Total 3139\n",
      "Precission:  0.708737864078\n",
      "Recall:  0.415954415954\n",
      "F1 Score:  0.524236983842\n",
      "*****************************************************************************\n",
      "\n",
      "\n",
      "TEST METRICS - DECISSION TREE CLASSIFIER\n",
      "True Positives: 53\n",
      "True Negatives: 1172\n",
      "False Positives: 40\n",
      "False Negatives: 117\n",
      "Total 3139\n",
      "Precission:  0.569892473118\n",
      "Recall:  0.311764705882\n",
      "F1 Score:  0.403041825095\n"
     ]
    }
   ],
   "source": [
    "true_positive = predictionAndLabels_train_dt[(predictionAndLabels_train_dt.label == 1) & (predictionAndLabels_train_dt.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_train_dt[(predictionAndLabels_train_dt.label == 0) & (predictionAndLabels_train_dt.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_train_dt[(predictionAndLabels_train_dt.label == 0) & (predictionAndLabels_train_dt.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_train_dt[(predictionAndLabels_train_dt.label == 1) & (predictionAndLabels_train_dt.prediction == 0.0)].count()\n",
    "print \"TRAIN METRICS - DECISSION TREE CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_dt.count()\n",
    "precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))\n",
    "print(\"*****************************************************************************\")\n",
    "true_positive = predictionAndLabels_test_dt[(predictionAndLabels_test_dt.label == 1) & (predictionAndLabels_test_dt.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_test_dt[(predictionAndLabels_test_dt.label == 0) & (predictionAndLabels_test_dt.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_test_dt[(predictionAndLabels_test_dt.label == 0) & (predictionAndLabels_test_dt.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_test_dt[(predictionAndLabels_test_dt.label == 1) & (predictionAndLabels_test_dt.prediction == 0.0)].count()\n",
    "print \"\\n\\nTEST METRICS - DECISSION TREE CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_dt.count()\n",
    "precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "treeModel = dt_Pipeline_model.stages[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned classification tree model:\n",
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4ee384872d95498b2989) of depth 5 with 55 nodes\n",
      "  If (feature 2 <= 0.12926183382985768)\n",
      "   If (feature 3 <= 0.02)\n",
      "    If (feature 64 in {1.0})\n",
      "     If (feature 2 <= 0.03028798411122145)\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 > 0.03028798411122145)\n",
      "      If (feature 17 in {0.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 17 not in {0.0})\n",
      "       Predict: 0.0\n",
      "    Else (feature 64 not in {1.0})\n",
      "     If (feature 61 in {1.0})\n",
      "      If (feature 23 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 23 not in {1.0})\n",
      "       Predict: 0.0\n",
      "     Else (feature 61 not in {1.0})\n",
      "      If (feature 66 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 66 not in {1.0})\n",
      "       Predict: 0.0\n",
      "   Else (feature 3 > 0.02)\n",
      "    If (feature 68 in {1.0})\n",
      "     If (feature 58 in {1.0})\n",
      "      If (feature 4 <= 0.17603211009174313)\n",
      "       Predict: 0.0\n",
      "      Else (feature 4 > 0.17603211009174313)\n",
      "       Predict: 1.0\n",
      "     Else (feature 58 not in {1.0})\n",
      "      If (feature 52 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 52 not in {1.0})\n",
      "       Predict: 0.0\n",
      "    Else (feature 68 not in {1.0})\n",
      "     If (feature 69 in {1.0})\n",
      "      If (feature 4 <= 0.21158256880733944)\n",
      "       Predict: 0.0\n",
      "      Else (feature 4 > 0.21158256880733944)\n",
      "       Predict: 0.0\n",
      "     Else (feature 69 not in {1.0})\n",
      "      If (feature 2 <= 0.051473022178086726)\n",
      "       Predict: 0.0\n",
      "      Else (feature 2 > 0.051473022178086726)\n",
      "       Predict: 1.0\n",
      "  Else (feature 2 > 0.12926183382985768)\n",
      "   If (feature 2 <= 0.2302217808672625)\n",
      "    If (feature 55 in {1.0})\n",
      "     If (feature 0 <= 0.13076923076923078)\n",
      "      If (feature 1 <= 0.0026619654998033377)\n",
      "       Predict: 1.0\n",
      "      Else (feature 1 > 0.0026619654998033377)\n",
      "       Predict: 0.0\n",
      "     Else (feature 0 > 0.13076923076923078)\n",
      "      If (feature 22 in {0.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 22 not in {0.0})\n",
      "       Predict: 0.0\n",
      "    Else (feature 55 not in {1.0})\n",
      "     If (feature 59 in {1.0})\n",
      "      If (feature 0 <= 0.1)\n",
      "       Predict: 0.0\n",
      "      Else (feature 0 > 0.1)\n",
      "       Predict: 1.0\n",
      "     Else (feature 59 not in {1.0})\n",
      "      If (feature 64 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 64 not in {1.0})\n",
      "       Predict: 0.0\n",
      "   Else (feature 2 > 0.2302217808672625)\n",
      "    If (feature 11 in {1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 11 not in {1.0})\n",
      "     If (feature 54 in {0.0})\n",
      "      If (feature 20 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 20 not in {1.0})\n",
      "       Predict: 0.0\n",
      "     Else (feature 54 not in {0.0})\n",
      "      If (feature 0 <= 0.46923076923076923)\n",
      "       Predict: 1.0\n",
      "      Else (feature 0 > 0.46923076923076923)\n",
      "       Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Learned classification tree model:\"\n",
    "print treeModel.toDebugString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Random Forest Classifier](../Images/rfc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_Pipeline = Pipeline(stages=preprocessiong_Stages+[rf]) \n",
    "rf_Pipeline_model = rf_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_rf = rf_Pipeline_model.transform(trainingData)\n",
    "test_predictions_rf = rf_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.895508123606\n",
      "Train Error = 0.104492\n",
      "Test set accuracy = 0.878437047757\n",
      "Test Error = 0.121563\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictionAndLabels_train_rf = train_predictions_rf.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(predictionAndLabels_train_rf)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracy))\n",
    "print(\"Train Error = %g\" % (1.0 - train_accuracy))\n",
    "\n",
    "predictionAndLabels_test_rf = test_predictions_rf.select(\"prediction\", \"label\")\n",
    "test_accuracy = evaluator.evaluate(predictionAndLabels_test_rf)\n",
    "print(\"Test set accuracy = \" + str(test_accuracy))\n",
    "print(\"Test Error = %g\" % (1.0 - test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN METRICS - RANDOM FOREST CLASSIFIER\n",
      "True Positives: 26\n",
      "True Negatives: 2785\n",
      "False Positives: 3\n",
      "False Negatives: 325\n",
      "Total 3139\n",
      "Precission:  0.896551724138\n",
      "Recall:  0.0740740740741\n",
      "F1 Score:  0.136842105263\n",
      "*****************************************************************************\n",
      "TEST METRICS - RANDOM FOREST CLASSIFIER\n",
      "True Positives: 5\n",
      "True Negatives: 1209\n",
      "False Positives: 3\n",
      "False Negatives: 165\n",
      "Total 3139\n",
      "Precission:  0.896551724138\n",
      "Recall:  0.0294117647059\n",
      "F1 Score:  0.0569550930997\n"
     ]
    }
   ],
   "source": [
    "true_positive = predictionAndLabels_train_rf[(predictionAndLabels_train_rf.label == 1) & (predictionAndLabels_train_rf.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_train_rf[(predictionAndLabels_train_rf.label == 0) & (predictionAndLabels_train_rf.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_train_rf[(predictionAndLabels_train_rf.label == 0) & (predictionAndLabels_train_rf.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_train_rf[(predictionAndLabels_train_rf.label == 1) & (predictionAndLabels_train_rf.prediction == 0.0)].count()\n",
    "print \"TRAIN METRICS - RANDOM FOREST CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_rf.count()\n",
    "precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))\n",
    "print(\"*****************************************************************************\")\n",
    "\n",
    "true_positive = predictionAndLabels_test_rf[(predictionAndLabels_test_rf.label == 1) & (predictionAndLabels_test_rf.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_test_rf[(predictionAndLabels_test_rf.label == 0) & (predictionAndLabels_test_rf.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_test_rf[(predictionAndLabels_test_rf.label == 0) & (predictionAndLabels_test_rf.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_test_rf[(predictionAndLabels_test_rf.label == 1) & (predictionAndLabels_test_rf.prediction == 0.0)].count()\n",
    "print \"TEST METRICS - RANDOM FOREST CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_rf.count()\n",
    "#precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradient Boosted Tree Classifier](../Images/gbtc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbt_Pipeline = Pipeline(stages=preprocessiong_Stages+[gbt]) \n",
    "gbt_Pipeline_model = gbt_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_gbt = gbt_Pipeline_model.transform(trainingData)\n",
    "test_predictions_gbt = gbt_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.931188276521\n",
      "Train Error = 0.0688117\n",
      "Test set accuracy = 0.88494934877\n",
      "Test Error = 0.115051\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictionAndLabels_train_gbt = train_predictions_gbt.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(predictionAndLabels_train_gbt)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracy))\n",
    "print(\"Train Error = %g\" % (1.0 - train_accuracy))\n",
    "\n",
    "predictionAndLabels_test_gbt = test_predictions_gbt.select(\"prediction\", \"label\")\n",
    "test_accuracy = evaluator.evaluate(predictionAndLabels_test_gbt)\n",
    "print(\"Test set accuracy = \" + str(test_accuracy))\n",
    "print(\"Test Error = %g\" % (1.0 - test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN METRICS - GRADIENT-BOOSTED TREE CLASSIFIER\n",
      "True Positives: 184\n",
      "True Negatives: 2739\n",
      "False Positives: 49\n",
      "False Negatives: 167\n",
      "Total 3139\n",
      "Precission:  0.789699570815\n",
      "Recall:  0.524216524217\n",
      "F1 Score:  0.630136986301\n",
      "*****************************************************************************\n",
      "TEST METRICS - GRADIENT-BOOSTED TREE CLASSIFIER\n",
      "True Positives: 53\n",
      "True Negatives: 1170\n",
      "False Positives: 42\n",
      "False Negatives: 117\n",
      "Total 3139\n",
      "Precission:  0.557894736842\n",
      "Recall:  0.311764705882\n",
      "F1 Score:  0.4\n"
     ]
    }
   ],
   "source": [
    "true_positive = predictionAndLabels_train_gbt[(predictionAndLabels_train_gbt.label == 1) & (predictionAndLabels_train_gbt.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_train_gbt[(predictionAndLabels_train_gbt.label == 0) & (predictionAndLabels_train_gbt.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_train_gbt[(predictionAndLabels_train_gbt.label == 0) & (predictionAndLabels_train_gbt.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_train_gbt[(predictionAndLabels_train_gbt.label == 1) & (predictionAndLabels_train_gbt.prediction == 0.0)].count()\n",
    "print \"TRAIN METRICS - GRADIENT-BOOSTED TREE CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_gbt.count()\n",
    "precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))\n",
    "print(\"*****************************************************************************\")\n",
    "true_positive = predictionAndLabels_test_gbt[(predictionAndLabels_test_gbt.label == 1) & (predictionAndLabels_test_gbt.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_test_gbt[(predictionAndLabels_test_gbt.label == 0) & (predictionAndLabels_test_gbt.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_test_gbt[(predictionAndLabels_test_gbt.label == 0) & (predictionAndLabels_test_gbt.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_test_gbt[(predictionAndLabels_test_gbt.label == 1) & (predictionAndLabels_test_gbt.prediction == 0.0)].count()\n",
    "print \"TEST METRICS - GRADIENT-BOOSTED TREE CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_gbt.count()\n",
    "precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multilayer Perceptron](../Images/mlp3_1.png)\n",
    "![Multilayer Perceptron](../Images/mlp4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 71 (features), two intermediate of size 5 and 4\n",
    "# and output of size 2 (classes)\n",
    "layers = [70, 50, 40, 2]\n",
    "# create the trainer and set its parameters\n",
    "mlp = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_Pipeline = Pipeline(stages=preprocessiong_Stages+[mlp]) \n",
    "mlp_Pipeline_model = mlp_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_mlp = mlp_Pipeline_model.transform(trainingData)\n",
    "test_predictions_mlp = mlp_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.948709780185\n",
      "Train Error = 0.0512902\n",
      "Test set accuracy = 0.879160636758\n",
      "Test Error = 0.120839\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictionAndLabels_train_mlp = train_predictions_mlp.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(predictionAndLabels_train_mlp)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracy))\n",
    "print(\"Train Error = %g\" % (1.0 - train_accuracy))\n",
    "\n",
    "predictionAndLabels_test_mlp = test_predictions_mlp.select(\"prediction\", \"label\")\n",
    "test_accuracy = evaluator.evaluate(predictionAndLabels_test_mlp)\n",
    "print(\"Test set accuracy = \" + str(test_accuracy))\n",
    "print(\"Test Error = %g\" % (1.0 - test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN METRICS - MULTI-LAYER PERCEPTRON CLASSIFIER\n",
      "True Positives: 268\n",
      "True Negatives: 2710\n",
      "False Positives: 78\n",
      "False Negatives: 83\n",
      "Total 3139\n",
      "Precission:  0.772334293948\n",
      "Recall:  0.763532763533\n",
      "F1 Score:  0.465089473906\n",
      "*****************************************************************************\n",
      "TEST METRICS - MULTI-LAYER PERCEPTRON CLASSIFIER\n",
      "True Positives: 73\n",
      "True Negatives: 1142\n",
      "False Positives: 70\n",
      "False Negatives: 97\n",
      "Total 3139\n",
      "Precission:  0.506944444444\n",
      "Recall:  0.429411764706\n",
      "F1 Score:  0.224842833636\n"
     ]
    }
   ],
   "source": [
    "true_positive = predictionAndLabels_train_mlp[(predictionAndLabels_train_mlp.label == 1) & (predictionAndLabels_train_mlp.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_train_mlp[(predictionAndLabels_train_mlp.label == 0) & (predictionAndLabels_train_mlp.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_train_mlp[(predictionAndLabels_train_mlp.label == 0) & (predictionAndLabels_train_mlp.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_train_mlp[(predictionAndLabels_train_mlp.label == 1) & (predictionAndLabels_train_mlp.prediction == 0.0)].count()\n",
    "print \"TRAIN METRICS - MULTI-LAYER PERCEPTRON CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_mlp.count()\n",
    "precission = true_positive / float(true_positive + false_positive + 1)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall+1)))\n",
    "print(\"*****************************************************************************\")\n",
    "true_positive = predictionAndLabels_test_mlp[(predictionAndLabels_test_mlp.label == 1) & (predictionAndLabels_test_mlp.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_test_mlp[(predictionAndLabels_test_mlp.label == 0) & (predictionAndLabels_test_mlp.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_test_mlp[(predictionAndLabels_test_mlp.label == 0) & (predictionAndLabels_test_mlp.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_test_mlp[(predictionAndLabels_test_mlp.label == 1) & (predictionAndLabels_test_mlp.prediction == 0.0)].count()\n",
    "print \"TEST METRICS - MULTI-LAYER PERCEPTRON CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_mlp.count()\n",
    "precission = true_positive / (float(true_positive + false_positive) + 1)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Linear SVM](../Images/lsvm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsvc_Pipeline = Pipeline(stages=preprocessiong_Stages+[lsvc]) \n",
    "lsvc_Pipeline_model = lsvc_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_lsvc = lsvc_Pipeline_model.transform(trainingData)\n",
    "test_predictions_lsvc = lsvc_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.888180949347\n",
      "Train Error = 0.111819\n",
      "Test set accuracy = 0.876989869754\n",
      "Test Error = 0.12301\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictionAndLabels_train_lsvc = train_predictions_lsvc.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(predictionAndLabels_train_lsvc)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracy))\n",
    "print(\"Train Error = %g\" % (1.0 - train_accuracy))\n",
    "\n",
    "predictionAndLabels_test_lsvc = test_predictions_lsvc.select(\"prediction\", \"label\")\n",
    "test_accuracy = evaluator.evaluate(predictionAndLabels_test_lsvc)\n",
    "print(\"Test set accuracy = \" + str(test_accuracy))\n",
    "print(\"Test Error = %g\" % (1.0 - test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN METRICS - Linear Support Vector Machine CLASSIFIER\n",
      "True Positives: 0\n",
      "True Negatives: 2788\n",
      "False Positives: 0\n",
      "False Negatives: 351\n",
      "Total 3139\n",
      "Precission:  0.0\n",
      "Recall:  0.0\n",
      "F1 Score:  0.0\n",
      "*****************************************************************************\n",
      "TEST METRICS - Linear Support Vector Machine CLASSIFIER\n",
      "True Positives: 0\n",
      "True Negatives: 1212\n",
      "False Positives: 0\n",
      "False Negatives: 170\n",
      "Total 3139\n",
      "Precission:  0.0\n",
      "Recall:  0.0\n",
      "F1 Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "true_positive = predictionAndLabels_train_lsvc[(predictionAndLabels_train_lsvc.label == 1) & (predictionAndLabels_train_lsvc.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_train_lsvc[(predictionAndLabels_train_lsvc.label == 0) & (predictionAndLabels_train_lsvc.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_train_lsvc[(predictionAndLabels_train_lsvc.label == 0) & (predictionAndLabels_train_lsvc.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_train_lsvc[(predictionAndLabels_train_lsvc.label == 1) & (predictionAndLabels_train_lsvc.prediction == 0.0)].count()\n",
    "print \"TRAIN METRICS - Linear Support Vector Machine CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_lsvc.count()\n",
    "precission = true_positive / float(true_positive + false_positive+1)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall+1)))\n",
    "print(\"*****************************************************************************\")\n",
    "true_positive = predictionAndLabels_test_lsvc[(predictionAndLabels_test_lsvc.label == 1) & (predictionAndLabels_test_lsvc.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_test_lsvc[(predictionAndLabels_test_lsvc.label == 0) & (predictionAndLabels_test_lsvc.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_test_lsvc[(predictionAndLabels_test_lsvc.label == 0) & (predictionAndLabels_test_lsvc.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_test_lsvc[(predictionAndLabels_test_lsvc.label == 1) & (predictionAndLabels_test_lsvc.prediction == 0.0)].count()\n",
    "print \"TEST METRICS - Linear Support Vector Machine CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_lsvc.count()\n",
    "precission = true_positive / float(true_positive + false_positive+1)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Naive Bayes](../Images/nbc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nbc = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbc_Pipeline = Pipeline(stages=preprocessiong_Stages+[nbc]) \n",
    "nbc_Pipeline_model = nbc_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions_nbc = nbc_Pipeline_model.transform(trainingData)\n",
    "test_predictions_nbc = nbc_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.882765211851\n",
      "Train Error = 0.117235\n",
      "Test set accuracy = 0.868306801737\n",
      "Test Error = 0.131693\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictionAndLabels_train_nbc = train_predictions_nbc.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(predictionAndLabels_train_nbc)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracy))\n",
    "print(\"Train Error = %g\" % (1.0 - train_accuracy))\n",
    "\n",
    "predictionAndLabels_test_nbc = test_predictions_nbc.select(\"prediction\", \"label\")\n",
    "test_accuracy = evaluator.evaluate(predictionAndLabels_test_nbc)\n",
    "print(\"Test set accuracy = \" + str(test_accuracy))\n",
    "print(\"Test Error = %g\" % (1.0 - test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN METRICS - Naive Bayes CLASSIFIER\n",
      "True Positives: 54\n",
      "True Negatives: 2717\n",
      "False Positives: 71\n",
      "False Negatives: 297\n",
      "Total 3139\n",
      "Precission:  0.432\n",
      "Recall:  0.153846153846\n",
      "F1 Score:  0.226890756303\n",
      "*****************************************************************************\n",
      "TEST METRICS - Naive Bayes CLASSIFIER\n",
      "True Positives: 24\n",
      "True Negatives: 1176\n",
      "False Positives: 36\n",
      "False Negatives: 146\n",
      "Total 3139\n",
      "Precission:  0.4\n",
      "Recall:  0.141176470588\n",
      "F1 Score:  0.208695652174\n"
     ]
    }
   ],
   "source": [
    "true_negative = predictionAndLabels_train_nbc[(predictionAndLabels_train_nbc.label == 0) & (predictionAndLabels_train_nbc.prediction == 0.0)].count()\n",
    "true_positive = predictionAndLabels_train_nbc[(predictionAndLabels_train_nbc.label == 1) & (predictionAndLabels_train_nbc.prediction == 1.0)].count()\n",
    "false_positive = predictionAndLabels_train_nbc[(predictionAndLabels_train_nbc.label == 0) & (predictionAndLabels_train_nbc.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_train_nbc[(predictionAndLabels_train_nbc.label == 1) & (predictionAndLabels_train_nbc.prediction == 0.0)].count()\n",
    "print \"TRAIN METRICS - Naive Bayes CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_nbc.count()\n",
    "precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))\n",
    "print(\"*****************************************************************************\")\n",
    "true_positive = predictionAndLabels_test_nbc[(predictionAndLabels_test_nbc.label == 1) & (predictionAndLabels_test_nbc.prediction == 1.0)].count()\n",
    "true_negative = predictionAndLabels_test_nbc[(predictionAndLabels_test_nbc.label == 0) & (predictionAndLabels_test_nbc.prediction == 0.0)].count()\n",
    "false_positive = predictionAndLabels_test_nbc[(predictionAndLabels_test_nbc.label == 0) & (predictionAndLabels_test_nbc.prediction == 1.0)].count()\n",
    "false_negative = predictionAndLabels_test_nbc[(predictionAndLabels_test_nbc.label == 1) & (predictionAndLabels_test_nbc.prediction == 0.0)].count()\n",
    "print \"TEST METRICS - Naive Bayes CLASSIFIER\"\n",
    "print \"True Positives:\", true_positive\n",
    "print \"True Negatives:\", true_negative\n",
    "print \"False Positives:\", false_positive\n",
    "print \"False Negatives:\", false_negative\n",
    "print \"Total\", predictionAndLabels_train_nbc.count()\n",
    "precission = true_positive / float(true_positive + false_positive)\n",
    "print \"Precission: \", precission\n",
    "recall = true_positive / float(true_positive + false_negative)\n",
    "print \"Recall: \", recall\n",
    "print \"F1 Score: \", (2*((precission * recall)/float(precission + recall)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
