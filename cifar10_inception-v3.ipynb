{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: (50000, 32, 32, 3)\n",
      "train_labels: (50000, 1)\n",
      "test_data: (10000, 32, 32, 3)\n",
      "test_labels: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train = np.load('C:\\\\Piazza\\\\Activity Lab\\\\CNN-Lab\\\\cifar10_cnn1\\\\cifar10_cnn\\\\cifar_train.npz')\n",
    "x_train = train['data']\n",
    "train_labels = train['labels']\n",
    "\n",
    "test = np.load('C:\\\\Piazza\\\\Activity Lab\\\\CNN-Lab\\\\cifar10_cnn1\\\\cifar10_cnn\\\\cifar_test.npz')\n",
    "x_test = test['data']\n",
    "test_labels = test['labels']\n",
    "\n",
    "print('train_data:', x_train.shape)\n",
    "print('train_labels:', train_labels.shape)\n",
    "print('test_data:', x_test.shape)\n",
    "print('test_labels:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "nb_classes = 10\n",
    "\n",
    "img_rows, img_cols = 32, 32    # input image dimensions\n",
    "img_channels = 3               # The CIFAR10 images are RGB.\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(train_labels, nb_classes)\n",
    "y_test = to_categorical(test_labels, nb_classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize all the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize(p, size):\n",
    "    return Image.fromarray(p).resize(size=(size,size))\n",
    "\n",
    "def resize_all(arr, size):\n",
    "    t = []\n",
    "    for i in range(arr.shape[0]):\n",
    "        t.append(np.array(resize(arr[i], size)))\n",
    "\n",
    "    return(np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = resize_all(x_train, 224)\n",
    "x_test = resize_all(x_test, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255.\n",
    "x_test /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 224, 224, 3)\n",
      "(10000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vivekb/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Get Inception architecture from keras.applications\n",
    "from keras.applications.inception_v3 import InceptionV3, GlobalAveragePooling2D\n",
    "\n",
    "trained_model = InceptionV3(include_top=False,weights='imagenet')\n",
    "\n",
    "x = trained_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "pred_inception= Dense(10,activation='softmax')(x)\n",
    "model = Model(inputs=trained_model.input,outputs=pred_inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vivekb/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "#making the layers of vgg16 non-trainable\n",
    "for layer in trained_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "#compiling the model\n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 228s - loss: 0.8907 - acc: 0.7034 - val_loss: 0.7739 - val_acc: 0.7437\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 187s - loss: 0.7291 - acc: 0.7529 - val_loss: 0.7491 - val_acc: 0.7527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2343a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 2\n",
    "model.fit(x_train[:5000], y_train[:5000],\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cifar10_transferlearning.h5')\n",
    "# model.save_weights('cifar10_transferlearning.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
