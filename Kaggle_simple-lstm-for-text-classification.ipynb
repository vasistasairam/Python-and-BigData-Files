{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d6fb32fd69316596e236eab5fb8cf77c848508c3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f674695f1742479cefdeec0e81ab469f7b6ec90f"
   },
   "source": [
    "### Load the data into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_uuid": "aca2f1d9da3f35d104763166fe4d25448410d8f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\Text_Classification_Kaggle\\\\spam.csv',delimiter=',',encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "53083ccecf39523cff290495a6cc768061ba9b46"
   },
   "source": [
    "Drop the columns that are not required for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "95a8b5d6f19cf42d4f55c6d2842faf1d0d55c1d0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "v1    5572 non-null object\n",
      "v2    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c7060084470000f39a2dcc15b656586dcd6e9fd"
   },
   "source": [
    "Understand the distribution better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "a12002f521dd8eaeb0f69a932cbf23815ffd09d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of ham and spam messages')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.v1)\n",
    "plt.xlabel('Label')\n",
    "plt.title('Number of ham and spam messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "353a8191f86c3a22843a729b5d4a5acefbf94be8"
   },
   "source": [
    "* Create input and output vectors.\n",
    "* Process the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "a1a345c1683e2fcc7173ecae867a5da87f2dde24",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.v2\n",
    "Y = df.v1\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5572, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "150e244a39b814d8a41bbe0e419bc5f28e457dd6"
   },
   "source": [
    "Split into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "aa3386af09469682c66cc53a1830a4e42f0e70b6",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5378d55c271e01480c1ac07f94ff99a80f900d6"
   },
   "source": [
    "### Process the data\n",
    "* Tokenize the data and convert the text to sequences.\n",
    "* Add padding to ensure that all the sequences have the same shape.\n",
    "* There are many ways of taking the *max_len* and here an arbitrary length of 150 is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "bdca14f2b8cd7bd7cb5ee66fd40ea522217c03c6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words = max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTokenizer:    allows to vectorize a text corpus, by turning each text into either a sequence of integers   \\n              (each integer being the index of a token in a dictionary) or into a vector where\\n              the coefficient for each token could be binary, based on word count, based on tf-idf...\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Tokenizer:    allows to vectorize a text corpus, by turning each text into either a sequence of integers   \n",
    "              (each integer being the index of a token in a dictionary) or into a vector where\n",
    "              the coefficient for each token could be binary, based on word count, based on tf-idf...\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad8706caa7a447fb49b44919fd109129e4082a93"
   },
   "source": [
    "### RNN\n",
    "Define the RNN structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "78fff25b8be1de575bff071a2027f3dd2b11b911",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name = 'inputs', shape = [max_len])\n",
    "    layer = Embedding(max_words, 50, input_length = max_len)(inputs)\n",
    "    layer = LSTM(32)(layer)\n",
    "    layer = Dense(256, name = 'FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1, name = 'out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs = inputs, outputs = layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d7c489e32bff6d12b8c08c07a91e9ba5d302e0e"
   },
   "source": [
    "Call the function and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_uuid": "a0ede32d4127e8b4990fd74fe97fadef9e565d17",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 32)                10624     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 69,329\n",
      "Trainable params: 69,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])    # pqarams 91648"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc2e0a3ec50d14c790b82d66f9255456ec6a69da"
   },
   "source": [
    "Fit on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_uuid": "98f6d6318352420ea49c532cda158f715f940f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3788 samples, validate on 948 samples\n",
      "Epoch 1/10\n",
      "3788/3788 [==============================] - 9s 2ms/step - loss: 0.3337 - acc: 0.8709 - val_loss: 0.1550 - val_acc: 0.9420\n",
      "Epoch 2/10\n",
      "3788/3788 [==============================] - 7s 2ms/step - loss: 0.1049 - acc: 0.9747 - val_loss: 0.0578 - val_acc: 0.9842\n",
      "Epoch 3/10\n",
      "3788/3788 [==============================] - 7s 2ms/step - loss: 0.0521 - acc: 0.9847 - val_loss: 0.0562 - val_acc: 0.9789\n",
      "Epoch 4/10\n",
      "3788/3788 [==============================] - 7s 2ms/step - loss: 0.0340 - acc: 0.9900 - val_loss: 0.0444 - val_acc: 0.9852\n",
      "Epoch 5/10\n",
      "3788/3788 [==============================] - 7s 2ms/step - loss: 0.0256 - acc: 0.9923 - val_loss: 0.0436 - val_acc: 0.9863\n",
      "Epoch 6/10\n",
      "3788/3788 [==============================] - 7s 2ms/step - loss: 0.0178 - acc: 0.9952 - val_loss: 0.0455 - val_acc: 0.9873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b4f68aceb8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix, Y_train, batch_size = 128, epochs = 10,\n",
    "          validation_split = 0.2, callbacks = [EarlyStopping(monitor = 'val_loss', min_delta = 0.0001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "448ab38c2f804e47df48eb45385393aaec168032"
   },
   "source": [
    "The model performs well on the validation set and this configuration is chosen as the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ccca7839445a7d663ee7bc425a16e247df3e0e5b"
   },
   "source": [
    "Process the test set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_uuid": "80036135a11387d952becaf2fecf653a65c02328",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b60d7d2bcc0aabf77c8c8766c59f8d73cd34547"
   },
   "source": [
    "Evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "0db183049b59d96388812a98efedfc865b7cc141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 1s 880us/step\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_uuid": "3e121ab83f4a0b9f7376ab24aa25d67051171f89",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.062\n",
      "  Accuracy: 0.986\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEmbeddings:     Embeddings(input_dim, output_dim, input_length)   ( Word Embedding Layer)\\n                Embeddingd is relatively low dimentional space comes from translated \\n                high dimentional vectors.\\n                Word embedding is the collective name for a set of language modeling \\n                and feature learning texhniques in NLP. words or phrases from the vocabulary\\n                are mapped to vectors of real numbers.\\n\\nLSTM:           (LSTM) networks are a type of RNN capable of learning order dependence in sequence prediction problems.\\n         \\nDense layer:     A dense layer is a classic fully connected neural network layer : each input node is connected to each output node.\\n                 The dense layer is fully connected layer, so all the neurons in a layer are connected to those in a next layer.\\n                 \\nActivation:      Their main purpose is to convert a input signal of a node in a A-NN to an output signal.  \\n\\nDropouts:        Dropout is a regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data.  \\n                 It is a very efficient way of performing model averaging with neural networks. \\n                 The term \"dropout\" refers to dropping out units (both hidden and visible) in a neural network.\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Embeddings:     Embeddings(input_dim, output_dim, input_length)   ( Word Embedding Layer)\n",
    "                Embeddingd is relatively low dimentional space comes from translated \n",
    "                high dimentional vectors.\n",
    "                Word embedding is the collective name for a set of language modeling \n",
    "                and feature learning texhniques in NLP. words or phrases from the vocabulary\n",
    "                are mapped to vectors of real numbers.\n",
    "\n",
    "LSTM:           (LSTM) networks are a type of RNN capable of learning order dependence in sequence prediction problems.\n",
    "         \n",
    "Dense layer:     A dense layer is a classic fully connected neural network layer : each input node is connected to each output node.\n",
    "                 The dense layer is fully connected layer, so all the neurons in a layer are connected to those in a next layer.\n",
    "                 \n",
    "Activation:      Their main purpose is to convert a input signal of a node in a A-NN to an output signal.  \n",
    "\n",
    "Dropouts:        Dropout is a regularization technique for reducing overfitting in neural networks by preventing complex   \n",
    "                 co-adaptations on training data. It is a very efficient way of performing model averaging with neural networks. \n",
    "                 The term \"dropout\" refers to dropping out units (both hidden and visible) in a neural network.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
